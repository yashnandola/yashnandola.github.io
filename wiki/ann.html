<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2021-09-21" />
  <title>Artificial Neural Networks</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Artificial Neural Networks</h1>
</header>
<nav id="TOC" role="doc-toc">
<h3 id="toc-title">Contents</h3>
<ul>
<li><a href="#bibliography">References</a></li>
</ul>
</nav>
<p>An Artificial Neural Network (ANN) with scalar output consists in a family of functions <span class="math inline">\(f\left(\cdot,\theta\right):\mathbb{R}^{n_{\mathrm{in}}}\to\mathbb{R}\)</span> parametrized by a vector of parameters <span class="math inline">\(\theta\in\mathbb{R}^{P}\)</span>.</p>
<p>The Neural Tangent Kernel (NTK) is a kernel <span class="math inline">\(\Theta:\mathbb{R}^{n_{\mathrm{in}}}\times\mathbb{R}^{n_{\mathrm{in}}}\to\mathbb{R}\)</span> defined by <span class="math display">\[\Theta\left(x,y;\theta\right)=\sum_{p=1}^{P}\partial_{\theta_{p}}f\left(x;\theta\right)\partial_{\theta_{p}}f\left(y;\theta\right).\]</span></p>
<p>In the language of kernel methods, the NTK <span class="math inline">\(\Theta\)</span> is the kernel associated with the feature map <span class="math inline">\(\left(x\mapsto\partial_{\theta_{p}}f\left(x;\theta\right)\right)_{p=1,\ldots,P}\)</span>. This vector is is the gradient of the following map for a fixed <span class="math inline">\(\theta\)</span>. <span class="math display">\[\begin{align}
  \mathbb{R}^{P} \rightarrow &amp; \mathbb{R}\\
  \alpha \rightarrow &amp; f(x;\theta).
\end{align}\]</span></p>
<p>Thereâ€™s some good description about all this on the <a href="https://en.wikipedia.org/wiki/Neural_tangent_kernel">wikipedia page</a>. <span class="citation" data-cites="JFH18">[<a href="#ref-JFH18" role="doc-biblioref">1</a>]</span> is a good starting point for NTK research.</p>
<h1 class="unnumbered" id="bibliography">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-JFH18" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">A. Jacot, F. Gabriel, &amp; C. Hongler, Neural tangent kernel: Convergence and generalization in neural networks. <em>arXiv:1806.07572</em>, (2018).</div>
</div>
</div>
<hr />
	<small>	<p class="date">This page was updated on September 21, 2021.<br>
		<a href="index.html">Main Page</a> </p>
      </small>
</body>
</html>
